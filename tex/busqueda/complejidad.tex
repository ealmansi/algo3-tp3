Antes de comenzar el análisis de complejidad vamos a aclarar lo siguiente:

En este algoritmo usamos la estructura Camino, que es una lista de ejes y además tiene el peso total $W_1$ y $W_2$. Y además usamos la estructura vecino, que tiene tres tipos: $TIPO1$ significa que es un vecino que surge de eliminar un nodo de la solución actual, $TIPO2$ que surge de agregar un nodo, o $TIPO3$, que surge de cambiar un nodo por otro. Además la estructura tiene una posición donde hay que hacer los cambios para pasar del camino actual al vecino (estos cambios se deducen según el tipo del vecino que sea). Por último la estructura cuenta con una lista de nodos a agregar al camino actual, si se cambia o agrega un nodo la lista tendrá un elemento y si se elimina un nodo la lista será vacía.

Utilizamos esta estructura para poder pasar de un camino a su vecino en una complejidad constante $O(1)$ ya que ésta cuenta con la información necesaria para saber cuáles son los cambios a realizar y dónde hay que realizarlos. Si no contáramos con esta estructura y tuviésemos simplemente otro camino deberíamos copiar el camino para actualizar la solución, lo que tendría una complejidad temporal lineal.

Dicho esto pasamos a analizar la complejidad de los algoritmos que buscan vecinos.

\begin{itemize}
 \item buscarVecinoAgregar

  Para analizar la complejidad de este algoritmo, es necesario aclarar que en la linea $3$ del mismo se verifica la guarda $j \in adyacentes(mejorSol_i,G) \cap adyacentes(mejorSol_{i+1},G)$. Esto se realiza una vez por cada iteración del $For$. Por lo tanto si cada vez que entramos en el $For$ revisamos todos los adyacentes de $mejorSol_i$ y $mejorSol_{i+2}$, lo cual tiene una complejidad lineal, a lo largo de todo el $For$ tendríamos una complejidad cuadrática. Sin embargo esto no es así ya que en nuestra implementación del algoritmo tenemos un grafo con listas de adyacencia en la que los nodos están ordenados, por lo tanto a lo largo de todo el $For$ tenemos una complejidad lineal y no cuadrática.

  Aclarado esto, observando el pseudocódigo que está situado en la sección anterior y teniendo en cuenta la última aclaración, podemos ver que la complejidad del algoritmo buscarVecinosAgregar es la siguiente:

  $O(1) + n*(n*(5*O(1))+O(1))$

  Por álgebra de órdenes:

  $n^2(O(1))$

  $O(n^2)$

  \item buscarVecinoQuitar

  Esta vez, en la guarda del $If$ de la linea $3$ usamos la operación $j \in adyacentes(mejorSol_i, G)$ que también tiene complejidad lineal.

  La complejidad del algoritmo es la siguiente:

  $O(1)+n*(O(1)+O(n)+5*O(1))$

  Por álgebra de órdenes:

  $O(1)+O(n)+O(n^2)+5*O(n)$

  $O(n^2+6n+1)$

  $O(n^2)$

  \item buscarVecinoCambiar

  En este algoritmo se usan las mismas operaciones que se utilizan en los algoritmos anteriores.

  Observando el pseudocódigo del algoritmo correspondiente ubicado en la sección anterior, podemos afirmar que la complejidad del algoritmo es la siguiente:

  $O(1) + n*(n*(O(1) +4*O(1))+O(1))$

  Por álgebra de órdenes:

  $n^2(O(1))$

  $O(n^2)$

\end{itemize}


Ahora pasamos a analizar la complejidad del algoritmo de búsqueda local.

En este algoritmo no sabemos a priori la cantidad de veces que se va a iterar durante la búsqueda de vecinos, o sea no sabemos cuantas veces va a iterar el ciclo principal del algoritmo. Llamamos a esa cantidad como el valor $c$. La complejidad de este algoritmo sa va a ver fuertemente afectada por este valor. 

La complejidad del algoritmo es la siguiente:

$O(1)+c*(3*O(n^2)+4*O(1))$

Por álgebra de órdenes:

$O(c(3n^2+O(1)))$

$O(cn^2)$

Como podemos observar la complejidad temporal resultante está ligada al valor de $c$. No podemos saber su valor pero si podemos acotarlo cuando estamos en el caso en el que el algoritmo tiene como entrada un grafo $G$ en el que sus aristas tienen pesos enteros.

Supongamos que la solución factible de peso $W2$ máximo tiene un peso $k$, llamamos a dicha solución $S_{max}$. Supongamos también que la solución factible con peso $W2$ mínimo, que es la solución óptima para el problema, tiene un peso $r$. Llamamos a dicha solución $S_{opt}$. En el caso en el que el grafo $G$ tenga pesos enteros sabemos que en cada iteración en el que el algoritmo mejore la solución, el peso de la solución disminuirá al menos en $1$. El caso en el que más veces podría iterar nuestro algoritmo en el caso de pesos enteros es el caso en el que tiene como solución inicial e itera, disminuyendo siempre el peso de la solución sólo en $1$ hasta llegar a la solución óptima. Podríamos decir entonces que vale la siguiente desigualdad:

$c \leq W2(solucionMaxima) - W2(solucionOptima)$  